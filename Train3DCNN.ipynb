{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Fused feature"
      ],
      "metadata": {
        "id": "WDi53d5V2iAW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMDEXxFWkces"
      },
      "outputs": [],
      "source": [
        "def load_feature(feat_name):\n",
        "  import numpy as np\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  feature = np.load('/fusedfeat/'+feat_name+'.npy')\n",
        "  labelid = np.load('/dataset/'+feat_name+'/label_75.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  X_train, X_test, y_train, y_test = train_test_split(feature, labelid, test_size=0.25, random_state=42)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "xt3Xw9Rs2qUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model"
      ],
      "metadata": {
        "id": "jpgfId0P2cjm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "la7CxMPXuNT7"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    from tensorflow.keras.models import Model, Sequential\n",
        "    from tensorflow.keras.layers import Dense, Input, Concatenate,Conv3D,ZeroPadding3D,TimeDistributed\n",
        "    from tensorflow.keras.regularizers import l2\n",
        "    from tensorflow.python.keras.layers.pooling import GlobalAveragePooling3D,MaxPooling3D,GlobalMaxPooling3D\n",
        "    from tensorflow.python.keras.layers.recurrent import LSTM\n",
        "    #from tensorflow.python.keras.layers import TimeDistributed\n",
        "    from tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,Dropout\n",
        "\n",
        "\n",
        "    input_layer = Input(shape=(16,7,7,2048))\n",
        "    encoded_sequence = BatchNormalization()(input_layer)\n",
        "    encoded_sequence = Conv3D(1024, kernel_size=(1, 2, 2),strides=1, activation='relu')(encoded_sequence)\n",
        "    encoded_sequence = BatchNormalization()(encoded_sequence)\n",
        "    encoded_sequence = Dropout(0.2)(encoded_sequence)\n",
        "    encoded_sequence = GlobalAveragePooling3D()(encoded_sequence)\n",
        "    hidden_layer = Dense(2048, activation=\"relu\")(encoded_sequence)\n",
        "    outputs = Dense(2, activation='softmax')(hidden_layer)\n",
        "    model = Model(input_layer, outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "y7RqAmHU3fdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZNXoS2ylTJm"
      },
      "outputs": [],
      "source": [
        "def train_model(feat_name,learningrate,batchsize):\n",
        "  from tensorflow.keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "  import numpy as np\n",
        "  X_train, X_test, y_train, y_test = load_feature(feat_name)\n",
        "  model = create_model()\n",
        "  optimizer_new=SGD(lr=lr, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=optimizer_new,loss='binary_crossentropy',metrics=['acc'])\n",
        "  checkpointer = ModelCheckpoint(filepath='/3d_model/model'+feat_name+'.hdf5', verbose=1, save_best_only=True)\n",
        "  history_new_cnlst=model.fit(X_train,y_train,batch_size=bz,epochs=500,validation_data=(X_test,y_test),callbacks=[checkpointer])\n",
        "  _, test_acc_cv = model.evaluate(X_test, y_test, verbose=0)\n",
        "  return test_acc_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ibY3SyL6Vcq_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "feat_name = ['hockey_features']\n",
        "learningrate = [0.01,0.001,0.0001]\n",
        "batchsize = [4,8]\n",
        "for feat in feat_name:\n",
        "  for bz in batchsize:\n",
        "    for lr in learningrate:\n",
        "      acc,t = train_model(feat,lr,bz)\n",
        "\n",
        "feat_name = ['movie_features']\n",
        "learningrate = [0.01,0.001,0.0001]\n",
        "batchsize = [4,8]\n",
        "for feat in feat_name:\n",
        "  for bz in batchsize:\n",
        "    for lr in learningrate:\n",
        "      acc,t = train_model(feat,lr,bz)\n",
        "\n",
        "feat_name = ['violentflow_features']\n",
        "learningrate = [0.01,0.001,0.0001]\n",
        "batchsize = [4,8]\n",
        "for feat in feat_name:\n",
        "  for bz in batchsize:\n",
        "    for lr in learningrate:\n",
        "      acc,t = train_model(feat,lr,bz)\n",
        "\n",
        "feat_name = ['all_features']\n",
        "learningrate = [0.01,0.001,0.0001]\n",
        "batchsize = [4,8]\n",
        "for feat in feat_name:\n",
        "  for bz in batchsize:\n",
        "    for lr in learningrate:\n",
        "      acc,t = train_model(feat,lr,bz)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "L4",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}